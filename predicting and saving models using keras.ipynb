{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting gast==0.4.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "textract 1.6.3 requires six==1.12.0, but you'll have six 1.15.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-win_amd64.whl (909 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.34.0-py2.py3-none-any.whl (152 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.24.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akish\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.6.20)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=4caaf69932c80d3a3df0c3f14075e5cdf88569f64329391b19bb2e49fb8d4f86\n",
      "  Stored in directory: c:\\users\\akish\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-win_amd64.whl size=33701 sha256=5c5ea0112317563a3f4991db2e3197c9c7d28b0db25659b834443e1601590b58\n",
      "  Stored in directory: c:\\users\\akish\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: six, grpcio, termcolor, astunparse, opt-einsum, keras-nightly, gast, protobuf, wrapt, keras-preprocessing, flatbuffers, absl-py, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard-plugin-wit, tensorboard-data-server, tensorboard, h5py, tensorflow-estimator, google-pasta, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.12.0\n",
      "    Uninstalling six-1.12.0:\n",
      "      Successfully uninstalled six-1.12.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.34.0 google-auth-oauthlib-0.4.5 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []\n",
    "\n",
    "for i in range(50):\n",
    "    # The ~5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "\n",
    "    # The ~5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    # The ~95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "\n",
    "    # The ~95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 - 2s - loss: 0.6477 - accuracy: 0.5757\n",
      "Epoch 2/30\n",
      "210/210 - 0s - loss: 0.6155 - accuracy: 0.6514\n",
      "Epoch 3/30\n",
      "210/210 - 0s - loss: 0.5842 - accuracy: 0.7052\n",
      "Epoch 4/30\n",
      "210/210 - 0s - loss: 0.5523 - accuracy: 0.7519\n",
      "Epoch 5/30\n",
      "210/210 - 0s - loss: 0.5195 - accuracy: 0.7862\n",
      "Epoch 6/30\n",
      "210/210 - 0s - loss: 0.4865 - accuracy: 0.8238\n",
      "Epoch 7/30\n",
      "210/210 - 0s - loss: 0.4541 - accuracy: 0.8419\n",
      "Epoch 8/30\n",
      "210/210 - 0s - loss: 0.4235 - accuracy: 0.8724\n",
      "Epoch 9/30\n",
      "210/210 - 0s - loss: 0.3958 - accuracy: 0.8819\n",
      "Epoch 10/30\n",
      "210/210 - 0s - loss: 0.3710 - accuracy: 0.8929\n",
      "Epoch 11/30\n",
      "210/210 - 0s - loss: 0.3495 - accuracy: 0.9005\n",
      "Epoch 12/30\n",
      "210/210 - 0s - loss: 0.3312 - accuracy: 0.9114\n",
      "Epoch 13/30\n",
      "210/210 - 0s - loss: 0.3159 - accuracy: 0.9167\n",
      "Epoch 14/30\n",
      "210/210 - 0s - loss: 0.3033 - accuracy: 0.9181\n",
      "Epoch 15/30\n",
      "210/210 - 0s - loss: 0.2929 - accuracy: 0.9290\n",
      "Epoch 16/30\n",
      "210/210 - 0s - loss: 0.2845 - accuracy: 0.9314\n",
      "Epoch 17/30\n",
      "210/210 - 0s - loss: 0.2776 - accuracy: 0.9290\n",
      "Epoch 18/30\n",
      "210/210 - 0s - loss: 0.2717 - accuracy: 0.9310\n",
      "Epoch 19/30\n",
      "210/210 - 0s - loss: 0.2666 - accuracy: 0.9352\n",
      "Epoch 20/30\n",
      "210/210 - 0s - loss: 0.2627 - accuracy: 0.9367\n",
      "Epoch 21/30\n",
      "210/210 - 0s - loss: 0.2592 - accuracy: 0.9352\n",
      "Epoch 22/30\n",
      "210/210 - 0s - loss: 0.2566 - accuracy: 0.9405\n",
      "Epoch 23/30\n",
      "210/210 - 0s - loss: 0.2537 - accuracy: 0.9381\n",
      "Epoch 24/30\n",
      "210/210 - 0s - loss: 0.2517 - accuracy: 0.9352\n",
      "Epoch 25/30\n",
      "210/210 - 0s - loss: 0.2498 - accuracy: 0.9376\n",
      "Epoch 26/30\n",
      "210/210 - 0s - loss: 0.2484 - accuracy: 0.9424\n",
      "Epoch 27/30\n",
      "210/210 - 0s - loss: 0.2467 - accuracy: 0.9386\n",
      "Epoch 28/30\n",
      "210/210 - 0s - loss: 0.2456 - accuracy: 0.9429\n",
      "Epoch 29/30\n",
      "210/210 - 0s - loss: 0.2444 - accuracy: 0.9433\n",
      "Epoch 30/30\n",
      "210/210 - 0s - loss: 0.2434 - accuracy: 0.9429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a69fae9b50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 - 1s - loss: 0.2408 - accuracy: 0.9429 - val_loss: 0.2576 - val_accuracy: 0.9429\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.2402 - accuracy: 0.9434 - val_loss: 0.2574 - val_accuracy: 0.9429\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.2394 - accuracy: 0.9429 - val_loss: 0.2565 - val_accuracy: 0.9429\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.2386 - accuracy: 0.9407 - val_loss: 0.2562 - val_accuracy: 0.9429\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.2380 - accuracy: 0.9434 - val_loss: 0.2555 - val_accuracy: 0.9429\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.2375 - accuracy: 0.9450 - val_loss: 0.2543 - val_accuracy: 0.9429\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.2369 - accuracy: 0.9434 - val_loss: 0.2528 - val_accuracy: 0.9429\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.2366 - accuracy: 0.9434 - val_loss: 0.2534 - val_accuracy: 0.9429\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.2362 - accuracy: 0.9434 - val_loss: 0.2532 - val_accuracy: 0.9429\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.2357 - accuracy: 0.9434 - val_loss: 0.2530 - val_accuracy: 0.9429\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.2354 - accuracy: 0.9481 - val_loss: 0.2516 - val_accuracy: 0.9429\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.2352 - accuracy: 0.9444 - val_loss: 0.2534 - val_accuracy: 0.9429\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.2348 - accuracy: 0.9434 - val_loss: 0.2525 - val_accuracy: 0.9429\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.2344 - accuracy: 0.9434 - val_loss: 0.2524 - val_accuracy: 0.9429\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.2342 - accuracy: 0.9434 - val_loss: 0.2525 - val_accuracy: 0.9429\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.2341 - accuracy: 0.9476 - val_loss: 0.2530 - val_accuracy: 0.9476\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.2337 - accuracy: 0.9466 - val_loss: 0.2513 - val_accuracy: 0.9429\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.2335 - accuracy: 0.9476 - val_loss: 0.2502 - val_accuracy: 0.9429\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.2333 - accuracy: 0.9439 - val_loss: 0.2508 - val_accuracy: 0.9429\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.2331 - accuracy: 0.9439 - val_loss: 0.2513 - val_accuracy: 0.9476\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2328 - accuracy: 0.9455 - val_loss: 0.2494 - val_accuracy: 0.9429\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2325 - accuracy: 0.9434 - val_loss: 0.2501 - val_accuracy: 0.9429\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2323 - accuracy: 0.9455 - val_loss: 0.2499 - val_accuracy: 0.9429\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2322 - accuracy: 0.9450 - val_loss: 0.2507 - val_accuracy: 0.9476\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2317 - accuracy: 0.9434 - val_loss: 0.2495 - val_accuracy: 0.9429\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2314 - accuracy: 0.9460 - val_loss: 0.2491 - val_accuracy: 0.9429\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2312 - accuracy: 0.9434 - val_loss: 0.2493 - val_accuracy: 0.9429\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2311 - accuracy: 0.9444 - val_loss: 0.2482 - val_accuracy: 0.9429\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2308 - accuracy: 0.9450 - val_loss: 0.2478 - val_accuracy: 0.9429\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2306 - accuracy: 0.9434 - val_loss: 0.2488 - val_accuracy: 0.9429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a6a2954a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels =  []\n",
    "test_samples = []\n",
    "\n",
    "for i in range(10):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "\n",
    "    # The 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    # The 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "\n",
    "    # The 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
    "\n",
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x= scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9755593  0.02444065]\n",
      "[0.0158186 0.9841814]\n",
      "[0.9767303  0.02326968]\n",
      "[0.975749   0.02425093]\n",
      "[0.05529352 0.94470644]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.9246857  0.07531427]\n",
      "[0.29856956 0.7014304 ]\n",
      "[0.10046976 0.89953023]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.04064754 0.9593525 ]\n",
      "[0.9765845  0.02341555]\n",
      "[0.12274209 0.8772578 ]\n",
      "[0.8682109 0.1317891]\n",
      "[0.9767512  0.02324882]\n",
      "[0.09114644 0.90885353]\n",
      "[0.9768901  0.02310995]\n",
      "[0.9767303  0.02326968]\n",
      "[0.97490066 0.02509937]\n",
      "[0.97608054 0.02391945]\n",
      "[0.01279246 0.9872075 ]\n",
      "[0.01422646 0.9857736 ]\n",
      "[0.6967007  0.30329925]\n",
      "[0.54970473 0.45029527]\n",
      "[0.97624755 0.02375249]\n",
      "[0.03664941 0.96335053]\n",
      "[0.3934865  0.60651356]\n",
      "[0.9759058  0.02409417]\n",
      "[0.6504269  0.34957314]\n",
      "[0.13715011 0.86284995]\n",
      "[0.8682109 0.1317891]\n",
      "[0.96369725 0.03630274]\n",
      "[0.54970473 0.45029527]\n",
      "[0.04064754 0.9593525 ]\n",
      "[0.9246857  0.07531427]\n",
      "[0.13715011 0.86284995]\n",
      "[0.6011349  0.39886513]\n",
      "[0.8121121 0.1878879]\n",
      "[0.02413124 0.97586876]\n",
      "[0.96369725 0.03630274]\n",
      "[0.6504269  0.34957314]\n",
      "[0.9767303  0.02326968]\n",
      "[0.97624755 0.02375249]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.3934865  0.60651356]\n",
      "[0.04506147 0.95493853]\n",
      "[0.07480519 0.9251948 ]\n",
      "[0.02413124 0.97586876]\n",
      "[0.01422646 0.9857736 ]\n",
      "[0.29856956 0.7014304 ]\n",
      "[0.01033914 0.98966086]\n",
      "[0.01954644 0.9804536 ]\n",
      "[0.9764166  0.02358343]\n",
      "[0.7778315  0.22216843]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.96645176 0.03354825]\n",
      "[0.02975877 0.97024125]\n",
      "[0.90942794 0.09057209]\n",
      "[0.7778315  0.22216843]\n",
      "[0.97558165 0.02441835]\n",
      "[0.09114644 0.90885353]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.97624755 0.02375249]\n",
      "[0.01954644 0.9804536 ]\n",
      "[0.05529352 0.94470644]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.44473657 0.55526346]\n",
      "[0.9690039  0.03099604]\n",
      "[0.02975877 0.97024125]\n",
      "[0.03664941 0.96335053]\n",
      "[0.01422646 0.9857736 ]\n",
      "[0.04992975 0.9500702 ]\n",
      "[0.9764166  0.02358343]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.03303098 0.966969  ]\n",
      "[0.03303098 0.966969  ]\n",
      "[0.6504269  0.34957314]\n",
      "[0.97640765 0.02359238]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.04064754 0.9593525 ]\n",
      "[0.9765845  0.02341555]\n",
      "[0.3934865  0.60651356]\n",
      "[0.9726547  0.02734528]\n",
      "[0.90942794 0.09057209]\n",
      "[0.01033914 0.98966086]\n",
      "[0.9768901  0.02310995]\n",
      "[0.29856956 0.7014304 ]\n",
      "[0.6967007  0.30329925]\n",
      "[0.12274209 0.8772578 ]\n",
      "[0.9767512  0.02324882]\n",
      "[0.02172085 0.9782792 ]\n",
      "[0.9765845  0.02341555]\n",
      "[0.9765845  0.02341555]\n",
      "[0.9757331  0.02426681]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.6967007  0.30329925]\n",
      "[0.49718952 0.5028105 ]\n",
      "[0.97624755 0.02375249]\n",
      "[0.9755593  0.02444065]\n",
      "[0.97429323 0.02570676]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.97524345 0.02475658]\n",
      "[0.84217656 0.15782347]\n",
      "[0.03664941 0.96335053]\n",
      "[0.21830745 0.7816925 ]\n",
      "[0.9246857  0.07531427]\n",
      "[0.9770487 0.0229513]\n",
      "[0.01954644 0.9804536 ]\n",
      "[0.44473657 0.55526346]\n",
      "[0.01150133 0.9884986 ]\n",
      "[0.9246857  0.07531427]\n",
      "[0.890509   0.10949103]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.9759153  0.02408463]\n",
      "[0.975749   0.02425093]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.06768426 0.93231577]\n",
      "[0.97472745 0.02527249]\n",
      "[0.9568228  0.04317723]\n",
      "[0.01279246 0.9872075 ]\n",
      "[0.8682109 0.1317891]\n",
      "[0.9759153  0.02408463]\n",
      "[0.06768426 0.93231577]\n",
      "[0.9362991  0.06370091]\n",
      "[0.97348624 0.02651371]\n",
      "[0.9754131 0.0245869]\n",
      "[0.97507256 0.0249274 ]\n",
      "[0.04506147 0.95493853]\n",
      "[0.11063062 0.8893694 ]\n",
      "[0.00835234 0.9916476 ]\n",
      "[0.8682109 0.1317891]\n",
      "[0.97607726 0.02392275]\n",
      "[0.11063062 0.8893694 ]\n",
      "[0.97429323 0.02570676]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.9710165  0.02898351]\n",
      "[0.9768901  0.02310995]\n",
      "[0.97507256 0.0249274 ]\n",
      "[0.9755593  0.02444065]\n",
      "[0.6011349  0.39886513]\n",
      "[0.9745532  0.02544679]\n",
      "[0.02975877 0.97024125]\n",
      "[0.02413124 0.97586876]\n",
      "[0.49718952 0.5028105 ]\n",
      "[0.97490066 0.02509937]\n",
      "[0.3934865  0.60651356]\n",
      "[0.01033914 0.98966086]\n",
      "[0.09114644 0.90885353]\n",
      "[0.01033914 0.98966086]\n",
      "[0.12274209 0.8772578 ]\n",
      "[0.97624755 0.02375249]\n",
      "[0.01150133 0.9884986 ]\n",
      "[0.9765695  0.02343049]\n",
      "[0.04506147 0.95493853]\n",
      "[0.09114644 0.90885353]\n",
      "[0.9767512  0.02324882]\n",
      "[0.97691673 0.02308325]\n",
      "[0.3934865  0.60651356]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.02413124 0.97586876]\n",
      "[0.00835234 0.9916476 ]\n",
      "[0.97524345 0.02475658]\n",
      "[0.6504269  0.34957314]\n",
      "[0.21830745 0.7816925 ]\n",
      "[0.9765695  0.02343049]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.07480519 0.9251948 ]\n",
      "[0.04506147 0.95493853]\n",
      "[0.0611964  0.93880355]\n",
      "[0.9759058  0.02409417]\n",
      "[0.3444786 0.6555214]\n",
      "[0.10046976 0.89953023]\n",
      "[0.97691673 0.02308325]\n",
      "[0.1845007  0.81549937]\n",
      "[0.9755593  0.02444065]\n",
      "[0.0611964  0.93880355]\n",
      "[0.29856956 0.7014304 ]\n",
      "[0.1845007  0.81549937]\n",
      "[0.6504269  0.34957314]\n",
      "[0.9750762  0.02492374]\n",
      "[0.9767512  0.02324882]\n",
      "[0.02413124 0.97586876]\n",
      "[0.9767512  0.02324882]\n",
      "[0.73930407 0.260696  ]\n",
      "[0.97437775 0.02562223]\n",
      "[0.01279246 0.9872075 ]\n",
      "[0.3444786 0.6555214]\n",
      "[0.3444786 0.6555214]\n",
      "[0.9755593  0.02444065]\n",
      "[0.02975877 0.97024125]\n",
      "[0.04064754 0.9593525 ]\n",
      "[0.97507256 0.0249274 ]\n",
      "[0.97507256 0.0249274 ]\n",
      "[0.97624755 0.02375249]\n",
      "[0.04506147 0.95493853]\n",
      "[0.11063062 0.8893694 ]\n",
      "[0.97348624 0.02651371]\n",
      "[0.15613939 0.84386057]\n",
      "[0.97558165 0.02441835]\n",
      "[0.9710165  0.02898351]\n",
      "[0.9765845  0.02341555]\n",
      "[0.97558165 0.02441835]\n",
      "[0.06768426 0.93231577]\n",
      "[0.0092933  0.99070674]\n",
      "[0.1845007  0.81549937]\n",
      "[0.97524345 0.02475658]\n",
      "[0.0092933  0.99070674]\n",
      "[0.0611964  0.93880355]\n",
      "[0.9759058  0.02409417]\n",
      "[0.21830745 0.7816925 ]\n",
      "[0.9767303  0.02326968]\n",
      "[0.07480519 0.9251948 ]\n",
      "[0.01422646 0.9857736 ]\n",
      "[0.975749   0.02425093]\n",
      "[0.9246857  0.07531427]\n",
      "[0.9767512  0.02324882]\n",
      "[0.02172085 0.9782792 ]\n",
      "[0.7778315  0.22216843]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.9605985  0.03940153]\n",
      "[0.9754131 0.0245869]\n",
      "[0.9750762  0.02492374]\n",
      "[0.9765695  0.02343049]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.01033914 0.98966086]\n",
      "[0.0092933  0.99070674]\n",
      "[0.3444786 0.6555214]\n",
      "[0.6504269  0.34957314]\n",
      "[0.02413124 0.97586876]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.97608054 0.02391945]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.97507256 0.0249274 ]\n",
      "[0.97558165 0.02441835]\n",
      "[0.11063062 0.8893694 ]\n",
      "[0.9768901  0.02310995]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.9519258  0.04807424]\n",
      "[0.05529352 0.94470644]\n",
      "[0.0611964  0.93880355]\n",
      "[0.9768901  0.02310995]\n",
      "[0.03664941 0.96335053]\n",
      "[0.9246857  0.07531427]\n",
      "[0.29856956 0.7014304 ]\n",
      "[0.94545233 0.05454766]\n",
      "[0.8121121 0.1878879]\n",
      "[0.02172085 0.9782792 ]\n",
      "[0.8121121 0.1878879]\n",
      "[0.9246857  0.07531427]\n",
      "[0.97507256 0.0249274 ]\n",
      "[0.9765845  0.02341555]\n",
      "[0.9745532  0.02544679]\n",
      "[0.9710165  0.02898351]\n",
      "[0.04992975 0.9500702 ]\n",
      "[0.3934865  0.60651356]\n",
      "[0.73930407 0.260696  ]\n",
      "[0.02975877 0.97024125]\n",
      "[0.9759153  0.02408463]\n",
      "[0.29856956 0.7014304 ]\n",
      "[0.03664941 0.96335053]\n",
      "[0.54970473 0.45029527]\n",
      "[0.9768901  0.02310995]\n",
      "[0.07480519 0.9251948 ]\n",
      "[0.97691673 0.02308325]\n",
      "[0.04506147 0.95493853]\n",
      "[0.10046976 0.89953023]\n",
      "[0.97691673 0.02308325]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.97348624 0.02651371]\n",
      "[0.15613939 0.84386057]\n",
      "[0.9770487 0.0229513]\n",
      "[0.01758577 0.9824142 ]\n",
      "[0.3934865  0.60651356]\n",
      "[0.29856956 0.7014304 ]\n",
      "[0.96369725 0.03630274]\n",
      "[0.9246857  0.07531427]\n",
      "[0.9764166  0.02358343]\n",
      "[0.97640765 0.02359238]\n",
      "[0.97624457 0.02375537]\n",
      "[0.97524345 0.02475658]\n",
      "[0.06768426 0.93231577]\n",
      "[0.02680173 0.9731983 ]\n",
      "[0.02680173 0.9731983 ]\n",
      "[0.01033914 0.98966086]\n",
      "[0.05529352 0.94470644]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.04064754 0.9593525 ]\n",
      "[0.9568228  0.04317723]\n",
      "[0.1845007  0.81549937]\n",
      "[0.84217656 0.15782347]\n",
      "[0.01150133 0.9884986 ]\n",
      "[0.9568228  0.04317723]\n",
      "[0.9519258  0.04807424]\n",
      "[0.49718952 0.5028105 ]\n",
      "[0.04506147 0.95493853]\n",
      "[0.97624755 0.02375249]\n",
      "[0.29856956 0.7014304 ]\n",
      "[0.975749   0.02425093]\n",
      "[0.12274209 0.8772578 ]\n",
      "[0.9754131 0.0245869]\n",
      "[0.01279246 0.9872075 ]\n",
      "[0.25638592 0.7436141 ]\n",
      "[0.6504269  0.34957314]\n",
      "[0.9765845  0.02341555]\n",
      "[0.04506147 0.95493853]\n",
      "[0.9710165  0.02898351]\n",
      "[0.04064754 0.9593525 ]\n",
      "[0.97558165 0.02441835]\n",
      "[0.01279246 0.9872075 ]\n",
      "[0.21830745 0.7816925 ]\n",
      "[0.9750762  0.02492374]\n",
      "[0.1845007  0.81549937]\n",
      "[0.97524345 0.02475658]\n",
      "[0.02975877 0.97024125]\n",
      "[0.97472745 0.02527249]\n",
      "[0.9690039  0.03099604]\n",
      "[0.02975877 0.97024125]\n",
      "[0.97472745 0.02527249]\n",
      "[0.04992975 0.9500702 ]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.02172085 0.9782792 ]\n",
      "[0.6011349  0.39886513]\n",
      "[0.97608054 0.02391945]\n",
      "[0.9754131 0.0245869]\n",
      "[0.97524345 0.02475658]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.6967007  0.30329925]\n",
      "[0.97624457 0.02375537]\n",
      "[0.9690039  0.03099604]\n",
      "[0.9768901  0.02310995]\n",
      "[0.3444786 0.6555214]\n",
      "[0.9767303  0.02326968]\n",
      "[0.49718952 0.5028105 ]\n",
      "[0.0158186 0.9841814]\n",
      "[0.1845007  0.81549937]\n",
      "[0.0158186 0.9841814]\n",
      "[0.97429323 0.02570676]\n",
      "[0.10046976 0.89953023]\n",
      "[0.9710165  0.02898351]\n",
      "[0.7778315  0.22216843]\n",
      "[0.3444786 0.6555214]\n",
      "[0.97490066 0.02509937]\n",
      "[0.97348624 0.02651371]\n",
      "[0.01279246 0.9872075 ]\n",
      "[0.15613939 0.84386057]\n",
      "[0.13715011 0.86284995]\n",
      "[0.97608054 0.02391945]\n",
      "[0.97437775 0.02562223]\n",
      "[0.9246857  0.07531427]\n",
      "[0.13715011 0.86284995]\n",
      "[0.97558165 0.02441835]\n",
      "[0.00835234 0.9916476 ]\n",
      "[0.13715011 0.86284995]\n",
      "[0.1845007  0.81549937]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.05529352 0.94470644]\n",
      "[0.9726547  0.02734528]\n",
      "[0.00835234 0.9916476 ]\n",
      "[0.73930407 0.260696  ]\n",
      "[0.9759153  0.02408463]\n",
      "[0.9605985  0.03940153]\n",
      "[0.9246857  0.07531427]\n",
      "[0.8682109 0.1317891]\n",
      "[0.6967007  0.30329925]\n",
      "[0.10046976 0.89953023]\n",
      "[0.0611964  0.93880355]\n",
      "[0.04506147 0.95493853]\n",
      "[0.1845007  0.81549937]\n",
      "[0.9690039  0.03099604]\n",
      "[0.02975877 0.97024125]\n",
      "[0.9764166  0.02358343]\n",
      "[0.0092933  0.99070674]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.01422646 0.9857736 ]\n",
      "[0.10046976 0.89953023]\n",
      "[0.01150133 0.9884986 ]\n",
      "[0.9764166  0.02358343]\n",
      "[0.97437775 0.02562223]\n",
      "[0.7778315  0.22216843]\n",
      "[0.975749   0.02425093]\n",
      "[0.13715011 0.86284995]\n",
      "[0.97507256 0.0249274 ]\n",
      "[0.0611964  0.93880355]\n",
      "[0.21830745 0.7816925 ]\n",
      "[0.0611964  0.93880355]\n",
      "[0.96369725 0.03630274]\n",
      "[0.15613939 0.84386057]\n",
      "[0.9519258  0.04807424]\n",
      "[0.97437775 0.02562223]\n",
      "[0.06768426 0.93231577]\n",
      "[0.03303098 0.966969  ]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.04992975 0.9500702 ]\n",
      "[0.9768901  0.02310995]\n",
      "[0.96645176 0.03354825]\n",
      "[0.975749   0.02425093]\n",
      "[0.9726547  0.02734528]\n",
      "[0.01033914 0.98966086]\n",
      "[0.73930407 0.260696  ]\n",
      "[0.1845007  0.81549937]\n",
      "[0.9745532  0.02544679]\n",
      "[0.9767512  0.02324882]\n",
      "[0.9710165  0.02898351]\n",
      "[0.01422646 0.9857736 ]\n",
      "[0.3444786 0.6555214]\n",
      "[0.08260883 0.9173911 ]\n",
      "[0.9757331  0.02426681]\n",
      "[0.96369725 0.03630274]\n",
      "[0.09114644 0.90885353]\n",
      "[0.97524345 0.02475658]\n",
      "[0.02413124 0.97586876]\n",
      "[0.02413124 0.97586876]\n",
      "[0.01279246 0.9872075 ]\n",
      "[0.04064754 0.9593525 ]\n",
      "[0.8121121 0.1878879]\n",
      "[0.9755593  0.02444065]\n",
      "[0.02680173 0.9731983 ]\n"
     ]
    }
   ],
   "source": [
    "for i in predict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predict, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[196  14]\n",
      " [ 10 200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAEmCAYAAAAuryiLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwUUlEQVR4nO3dd5yU1dnG8d8FKDZUEFBEscUSRUUFazTYa0QTOxpsscQSY0zUV2N9TSyYxERji0YUxW4sWPA1YktUiqggduwIIhYUG3C/f5yzOqy7s8uWmdnh+uYzH2bP8zxn7hmz9545zymKCMzMrPW1K3cAZmbzCydcM7MSccI1MysRJ1wzsxJxwjUzKxEnXDOzEnHCtTZD0sKS7pb0iaRbmlHPQEkjWjK2cpB0n6RB5Y7DGs8J11qcpP0kjZb0maTJOTH8qAWq3gNYGlgqIvZsaiURcX1EbNcC8cxFUn9JIen2WuXr5vKRjaznDElDGzovInaMiCFNDNfKwAnXWpSk44G/AH8gJcdewN+BAS1Q/QrAyxExqwXqai0fAJtKWqqgbBDwcku9gBL/7rZFEeGHHy3yAJYAPgP2LHJOR1JCfi8//gJ0zMf6A+8AvwGmApOBg/KxM4GvgW/yaxwCnAEMLah7RSCADvnnA4HXgRnAJGBgQfnjBddtCowCPsn/blpwbCRwNvBErmcE0LWe91YT/2XAUbmsfS47DRhZcO5FwNvAp8AYYPNcvkOt9/lsQRzn5Di+AH6Qyw7Nxy8Fbi2o/zzgIUDl/v+FH989/FfSWtImwELAHUXOOQXYGOgDrAtsCJxacHwZUuLuSUqql0jqHBGnk1rNN0XEYhFxVbFAJC0K/BXYMSI6kZLquDrO6wIMz+cuBfwJGF6rhbofcBDQHVgQOKHYawPXAj/Pz7cHJpD+uBQaRfoMugA3ALdIWigi7q/1PtctuOYA4DCgE/Bmrfp+A6wj6UBJm5M+u0GRs69VBidca0lLAdOi+Ff+gcBZETE1Ij4gtVwPKDj+TT7+TUTcS2rlrd7EeOYAvSUtHBGTI2JCHefsDLwSEddFxKyIGAa8CPyk4Jx/RsTLEfEFcDMpUdYrIv4DdJG0OinxXlvHOUMj4sP8mheSWv4Nvc9rImJCvuabWvXNBPYn/cEYChwTEe80UJ+VmBOutaQPga6SOhQ5Z1nmbp29mcu+raNWwp4JLDavgUTE58DewBHAZEnDJa3RiHhqYupZ8PP7TYjnOuBoYEvqaPFL+o2kiXnExcekVn3XBup8u9jBiHia1IUi0h8GqzBOuNaS/gt8CexW5Jz3SDe/avTi+1+3G+tzYJGCn5cpPBgRD0TEtkAPUqv1ykbEUxPTu02MqcZ1wC+Be3Pr81v5K/+JwF5A54hYktR/rJrQ66mzaPeApKNILeX3gN81OXJrNU641mIi4hPSzaFLJO0maRFJC0jaUdL5+bRhwKmSuknqms9vcAhUPcYBW0jqJWkJ4OSaA5KWlrRr7sv9itQ1MbuOOu4FVstD2TpI2htYE7iniTEBEBGTgB+T+qxr6wTMIo1o6CDpNGDxguNTgBXnZSSCpNWA/yV1KxwA/E5Sn6ZFb63FCddaVET8CTiedCPsA9LX4KOBf+VT/hcYDTwHPA+MzWVNea0HgZtyXWOYO0m2I91Ieg+YTkp+v6yjjg+BXfK5H5JahrtExLSmxFSr7scjoq7W+wPAfaShYm+SvhUUdhfUTOr4UNLYhl4nd+EMBc6LiGcj4hXgf4DrJHVsznuwliXfxDQzKw23cM3MSsQJ18wMkLS8pIfz6JEJkn6Vy7tIelDSK/nfzgXXnCzpVUkvSdq+wddwl4KZGUjqAfSIiLGSOpHuC+xGmpk4PSLOlXQSaWTJiZLWJN0E3pA0vPD/gNUioq6bs4BbuGZmAOTJMWPz8xnARNJ47AFAzSJBQ/hu2OMA4MaI+CqPSnmVlHzrVWyAulUgdVg41HGJcodR9fqssVy5Q5gvPDN2zLSI6NYSdbVffIWIWV8UPSe++GACaVRIjSsi4ora50laEVgPeApYOiImQ0rKkrrn03oCTxZc9g5zT5j5HifcNkYdl6DjWgPLHUbVe/SxC8odwnyh00Lta8/ya7KY9QUdV9+r6Dlfjrvky4joW+wcSYsBtwHHRcSnkuo9ta4witXthGtm1UGCdu2bWYUWICXb6yOiZl3jKZJ65NZtD9JKdpBatMsXXL4cDcyadB+umVUPtSv+KHZpaspeBUzME3hq3EVa05j8750F5ftI6ihpJWBV4Olir+EWrplViWa3cDcjTYt+XtK4XPY/wLnAzZIOAd4C9gSIiAmSbgZeIE3VPqrYCAVwwjWzalJ/f2uDIuJx6u6XBdi6nmvOIS0M3yhOuGZWHUSD3Qbl5oRrZlWi+TfNWpsTrplVj2Z0KZSCE66ZVYcWGBbW2pxwzax6uA/XzKwUBO3dwjUza30epWBmVkK+aWZmVgq+aWZmVjruUjAzKwEPCzMzKyH34ZqZlYJbuGZmpeFhYWZmpSInXDOzkmn+FjtXA7sAUyOidy67CVg9n7Ik8HFE9MkbTU4EXsrHnoyII4rV74RrZtWj+TfNrgEuBq6tKYiIvb+rXhcCnxSc/1pE9Gls5U64ZlYdWmBYWEQ8mluudVQvAXsBWzW1/sru8DAzmweSij6ArpJGFzwOm4fqNwemRMQrBWUrSXpG0iOSNm+oArdwzawqSKB2DXYpTIuIvk18iX2BYQU/TwZ6RcSHkjYA/iVprYj4tL4KnHDNrEp824pt+ZqlDsBPgQ1qyiLiK+Cr/HyMpNeA1YDR9dXjhGtmVaO1Ei6wDfBiRLxT8FrdgOkRMVvSysCqwOvFKnEfrplVjXbt2hV9NETSMOC/wOqS3pF0SD60D3N3JwBsATwn6VngVuCIiJherH63cM2sOig/miEi9q2n/MA6ym4DbpuX+p1wzawqCDWqFVtOTrhmVjVasQ+3RTjhmlnVcMI1MyuFxo3DLSsnXDOrCmrFcbgtxQnXzKqGW7hmZqUg9+GamZVMpQ8Lq+zorE247NS9efP+Mxg97IRvy9ZetQcjrzqGUTecwK0XHkynRTt+e6z3D9KxMTf+llE3nEDHBf13f14dedghrLT8Mmy4/jrfO3bRny+k00LtmTZtWhkiK5+aPtwGVgsrKydca7brho9iwK+unKvs0lP24tSLh9Nvv8HcNXI8v95/SwDat2/H1WfuxzHn3soG+1zA9kf+nW9mzS5H2G3awAMGccdd936v/J233+bhhx5k+eV7lSGqCqAGHmXmhGvN9sQzrzP905lzla3aqzuPP5PW8fj3Uy+z25ZrA7DNRqsx/tXJPP/KZACmfzKTOXOitAFXgR9tvgWdO3f5XvlJvzues/9wXkW05kpOzV9LobWVPwKrSi+8/j67bLEWAD/dZh2WW3pJAFbt1Y2I4K6/HsZ/rv01xx+wZRmjrC7D77mLZZftydrrrFvuUMrGXQolIKmvpL/Wc+wNSV1b4DXWkDQur+6+iqRjJU2UdH0T6jpO0iLNjamSHX72TRy+x2Y8MeQ4FltkIb7O3QYd2rdn0z4rcdDvr2frX1zMrv1707/fqmWOtu2bOXMmg8/7I6ecdma5QykrtVPRR7lVxd2KiBhNkUV/W8huwJ0RcTqApF8CO0bEpCbUdRwwFJjZwHlt1stvTuUnx14BwA96dWXHzX4IwLtTP+axsa/z4SefA3D/ExNZb/WejBz1Sr11WcMmvf4ab7wxiU37rQfAu+++w+Yb92Xk40+y9DLLlDm60qiUVmwxJW/hSloxtwyvlDRB0ghJC+djfSQ9Kek5SXdI6lzH9XtKGi/pWUmP5rL+ku7Jz5fKdT4j6XIKusol7S/p6dxSvVzS93ack7RB3p9ojKQHJPWQtBMpSR4q6WFJlwErA3dJ+rWkRSVdLWlUft0Bua72kgZLej6/p2MkHQssCzyc62ov6Zr8np6X9OuW/szLoVvnxYD0S3DSwdty5e3/BeDBJ1+i9w96sHDHBWjfvh2br78KEydNKWeoVWGt3msz6e33mfDy60x4+XV69lyOx54cPd8k2xruw63bqsAlEbEW8DHws1x+LXBiRKwDPA+cXse1pwHbR8S6wK51HD8deDwi1gPuAnoBSPohsDewWd7WeDYwsPBCSQsAfwP2iIgNgKuBcyLiXuAy4M8RsWXee/49YMuI+DNwCvDviOgHbAlcIGlR4DBgJWC9/J6uj4i/Fly7JdAH6BkRvSNibeCftd+QpMNqNr2LWZXXKB5y9v6MvOpYVluhO6/e/XsG7bohe223Hs/dehLP3nIikz/4lGvvfhqAj2d8wV9veITHhxzHU0OPZ9xL73L/ExPL/A7anoMO2I+t+2/GKy+/xOqr9GLIP68qd0iVoZmjFHLDaaqk8QVlZ0h6NzfUxuUGWM2xkyW9KuklSds3VH+5uhQmRcS4/HwMsKKkJYAlI+KRXD4EuKWOa58ArpF0M3B7Hce3IO09REQMl/RRLt+atB/RqPy1Y2Fgaq1rVwd6Aw/mc9qTNopryHbArpJqBqIuREr02wCXRcSsHE9dq8G/Dqws6W/AcGBE7RMi4grgCoB2iy5Tcbf0B/1+aJ3ll9z0WJ3lN94/lhvvH9uaIVW9f153Q9HjE14uutNL1WqBLoVrgItJjb9Cf46IwbVea03SThBrkb61/p+k1SKi3nGO5Uq4XxU8n01Kfo0SEUdI2gjYGRgnqU9dp9VRJmBIRJxcpHoBEyJik8bGU3DdzyLipbkK03/9ogkyIj6StC6wPXAUad/7g+fx9c3mexK0a+aNsYh4VNKKjTx9AHBj3kxykqRXgQ1JW/TUqfydGllEfAJ8pO/2dj8AeKT2eZJWiYinIuI0YBqwfK1THiV3FUjaEajpB34I2ENS93ysi6QVal37EtBN0ib5nAUkrdWI8B8AjskJFknr5fIRwBFKO34iqWbg5AygUy7rCrTL23X8Hli/Ea9nZt/TqJlmXWu65/LjsEZWfnS+D3N1wb2lnsDbBee8k8vqVTEJNxtE6v98jtS3eVYd51yQby6NJyXXZ2sdPxPYQtJY0lf9twAi4gXgVGBErv9BoEfhhRHxNbAHcJ7SxnDjgE0bEffZwAKkDeXG558B/pFfv2ajuf1y+RXAfZIeJv0HGilpHOnrTLEWuJkV0a6dij6AaRHRt+BxRSOqvRRYhZSTJgMX5vK6mtNFv9EqouK6BK2IdosuEx3XGtjwidYsHzx2QblDmC90Wqj9mIjo2xJ1LdRjtVhx0N+KnvPSeTs0+Hq5S+GeiOhd7JikkwEi4o/52APAGRFR+V0KZmbNIaB9exV9NKleqfCb8O5AzQiGu4B9JHWUtBJp9NXTxeqqiokPZmbQ/FEKkoYB/Ul9ve+Qhpn2zzfnA3gDOBwgIibk0VIvALOAo4qNUAAnXDOrFkojFZojIvato7jeQc4RcQ5wTmPrd8I1s6ogVBGzyYpxwjWzqlHhSyk44ZpZlWiBiQ+tzQnXzKqC8CaSZmYlU+H51gnXzKqHuxTMzEpB7lIwMyuJNCzMCdfMrCQqvIHrhGtmVcLDwszMSsPDwszMSsgJ18ysRNylYGZWCi2wWlhrqzfh5l1k690OIiKObZWIzMyaoCWGhUm6GtgFmFqz44OkC4CfAF8DrwEHRcTHefeHiaS9EAGejIgjitVfrIU7ulmRm5mVWLvW2Sb9QeDkiJgl6TzSvoMn5mOvRUSfxlZeb8KNiCGFP0taNCI+b2zFZmal1FrbpEfEiIIfnyRtNNskDa7WK2kTSS+Qms5IWlfS35v6gmZmraWdij9o+jbpNQ4G7iv4eSVJz0h6RNLmDV3cmJtmfwG2J22YRkQ8K2mLeQzSzKzVNWJY2LSm7hIs6RTS3mXX56LJQK+I+FDSBsC/JK0VEZ/WV0ejRilExNu13kjRjdLMzEpNtEgfbt11S4NIN9O2jogAiIivgK/y8zGSXgNWo8j9r8Yk3LclbQqEpAWBY8ndC2ZmlaQ1huFK2oF0k+zHETGzoLwbMD0iZktambRN+uvF6mpMwj0CuAjoCbwLPAAc1cTYzcxah1pkWFhd26SfDHQEHszf9GuGf20BnCVpFulb/xERMb1Y/Q0m3IiYBgxszpswM2ttLdGlMC/bpEfEbcBt81J/Y0YprCzpbkkfSJoq6c7cfDYzqyjt2qnoo9was4n7DcDNQA9gWeAWYFhrBmVmNq+khh/l1piEq4i4LiJm5cdQikz5NTMrl3ZS0Ue5FVtLoUt++rCkk4AbSYl2b2B4CWIzM5snlZBUiyl202wMKcHWvIPDC44FcHZrBWVmNq/STbNyR1FcsbUUViplIGZmzdICw8JaW6NmmknqDawJLFRTFhHX1n+FmVnptfkdHySdThoIvCZwL7Aj8DhzL19mZlZWAtpXeAu3MaMU9gC2Bt6PiIOAdUmzLszMKooaeJRbY7oUvoiIOZJmSVocmAp44oOZVRSpbY9SqDFa0pLAlaSRC58BT7dmUGZmTdHmb5pFxC/z08sk3Q8sHhHPtW5YZmbzrsIbuEUnPqxf7FhEjG2dkMzM5p2kir9pVqyFe2GRYwFs1cKxWCOst8ZyPPGfYv9prCV07nd0uUOwJmizw8IiYstSBmJm1lyNGXZVTpUen5lZo9SMwy32aLAO6eq8DO34grIukh6U9Er+t3PBsZMlvSrpJUnbN1S/E66ZVY1G7NrbkGuAHWqVnQQ8FBGrAg/ln5G0JrAPsFa+5u+S2heNb57ejZlZhZKa38KNiEeB2tvkDACG5OdDgN0Kym+MiK8iYhLwKrBhsfobs+ODJO0v6bT8cy9JRSs1MyuHRixA3lXS6ILHYY2odumImAyQ/+2ey3sCbxec904uq1djJj78HZhDGpVwFjCDtI9Pv0Zca2ZWEgI6NDxKYVpE9G3Bl6yt6OYMjelS2CgijgK+BIiIj4AF5z02M7PW1Upb7EyR1CPVrx6k5Q0gtWiXLzhvOeC9YhU1JuF+kzuCI79gN1KL18ysYqiB7XWasc7CXcCg/HwQcGdB+T6SOkpaCViVBpY9aEyXwl+BO4Duks4hrR52alOiNjNrTe2bOQxA0jDScrRdJb0DnA6cC9ws6RDgLWBPgIiYIOlm4AVgFnBURMwuVn9j1lK4XtIY0hKNAnaLiIlNf0tmZi0vbbHTvJlmEbFvPYe2ruf8c4BzGlt/YxYg7wXMBO4uLIuItxr7ImZmrU7Nb+G2tsZ0KQznu80kFwJWAl4iDfY1M6sYqohlxuvXmC6FtQt/zquIHV7P6WZmZSGgQxW0cOcSEWMleQyumVWcNrtaWA1Jxxf82A5YH/ig1SIyM2uCdNOs3FEU15gWbqeC57NIfbq3tU44ZmZNpMrftbdows0THhaLiN+WKB4zsyZp0y1cSR0iYlaxrXbMzCqHaN+G+3CfJvXXjpN0F3AL8HnNwYi4vZVjMzNrNNGGN5Es0AX4kLRaWM143ACccM2scgg6VHifQrGE2z2PUBjPd4m2RtElyMzMSq2tt3DbA4vRhDUfzczKoblrKbS2Ygl3ckScVbJIzMyaQUD7ys63RRNuhYduZlZAbXumWZ3LkZmZVaLUwm2jCTciau9caWZW0ZqTbiWtDtxUULQycBqwJPALvlvS4H8i4t6mvMY8L15jZlapmtPAjYiXgD6pHrUH3iXtdnMQ8OeIGNzc+JxwzawqqGVnmm0NvBYRb7Zkv3CFrx5pZtZ4koo+SHuVjS54HFZPVfsAwwp+PlrSc5KultS5qfE54ZpZdRCN2bV3WkT0LXhc8b1qpAWBXUnLGQBcCqxC6m6YDFzY1BCdcM2sKoiU0Io9GmlHYGxETAGIiCkRMTsi5gBXAhs2NUYnXDOrGo1o4TbGvhR0J0jqUXBsd9JyB03im2ZmVjWae39L0iLAtsy9b+P5kvqQljR4g2bs6eiEa2ZVIXUpNC/jRsRMYKlaZQc0q9ICTrhmViXmqdugLJxwzaxqVHi+dcI1s+ogVf5aCh6lYC3q8EMPptey3dmgT+9vy6ZPn87OO2xL7x+uys47bMtHH31UxgjbpuWWXpL7rziWZ247lTG3nsJR+/YHoPPii3DPpUfz/J2ncc+lR7Nkp4W/veaEg7dj/J2n8+wdv2ebTX5YpshLSyr+KDcnXGtRBww6kDvvuX+ussHnn0v/rbZm/MRX6L/V1gw+/9wyRdd2zZo9h5P+dDvr/ex/+fHPB3P43luwxsrLcMJB2zLy6ZdYe8BZjHz6JU44aDsA1lh5Gfbcfn3W3+Mcdj3q71x08l60q/DtZ5qrZrWwYo9yc8K1FvWjzbegS5cuc5Xdc/ed7H/AIAD2P2AQd9/1rzJE1ra9P+1Txr34DgCfzfyKFye9z7LdlmSX/usw9O6nABh691P8ZMt1ANil/zrc8sBYvv5mFm++9yGvvT2Nfr1XLFf4JaMG/lduTrjW6qZOmUKPHmnseI8ePfhg6tQyR9S29erRhT6rL8eo8W/QfalOvD/tUyAl5W5dOgHQs9sSvPP+d1037079iGW7L1GWeEtpvuxSkLSipCbPxsh1fDYP5/5D0pp1lB8o6eLmxFFQ1wWSJuR/u0l6StIzkjafx3r6SNqpJWKy+c+iCy/IsMGH8tvBtzHj8y/rP7GO7BJVvhNhW+hSqIpRChFxaAle5nCgW0R8JWkf4MWIGNSEevoAfYEmLWDcFnVfemkmT55Mjx49mDx5Mt26dy93SG1Shw7tGDb4F9x032ju/PezAEz9cAbLdF2c96d9yjJdF+eD6TMAeHfqxyy3zHeLWvXs3pnJH3xSlrhLpzK6DYppzS6F9pKuzK3CEZIWBpD0C0mjJD0r6bY8lQ5JK0n6bz52dl0VSlpU0vB87XhJe+fykZL65ucHSXpZ0iPAZgXXdsuvNyo/Nquj/va5BTsqL8V2eC6/C1gUeErSicD5wE6SxklaWNJ2Ofaxkm6RtFi+rp+k/+R4n5a0BHAWsHe+dm9JP87Px+UWc6cW+y9QIXbeZVeGXjcEgKHXDWGXnwwoc0Rt02WnD+SlSe/z16H//rZs+CPPs/9PNgJg/59sxD0jn0vlI59jz+3XZ8EFOrDCskvxg17dGDX+jXKEXTqCdg08yq01W7irAvtGxC8k3Qz8DBgK3B4RVwJI+l/gEOBvwEXApRFxraSj6qlzB+C9iNg5Xz9Xp1ReZOJMYAPgE+Bh4Jl8+CLSqu2PS+oFPADUHitzCPBJRPST1BF4QtKIiNhV0mcR0Se/zhSgb0QcLakrcCqwTUR8nhPy8ZLOJW3XsXdEjJK0ODCTtGVH34g4Otd1N3BURDyRE/X3vifmNTsPA1i+V696P/BK8PP99+WxR0Yybdo0VllxOX5/2pmc8LuT2H/fvRjyz6tYfvleXH/jLQ1XZHPZtM/KDNxlI55/+V2evPEkAE6/+C4G//NBhp53MIN224S3J3/EwN9dBcDE19/nthHP8MxtpzBr9hyOO/dm5syp7j4F0ba3SW+uSRExLj8fA6yYn/fOiXZJYDFS4oPUGv1Zfn4dcF4ddT4PDJZ0HnBPRDxW6/hGwMiI+ABA0k3AavnYNsCaBau3Ly6pU0TMKLh+O2AdSXvkn5cg/eGYVOR9bgysSUrOAAsC/wVWJ201PwogIj7NMdW+/gngT5KuJ/0xeqf2CXnNzisANtigb0X/1lw7dFid5feNeKjEkVSX/4x7nYXXO7rOYzsd8bc6y8+/6gHOv+qBOo9VqwrPt62acL8qeD4bqBmRfQ2wW0Q8K+lAoH/BeUWTSUS8LGkDYCfgj7n1eVbt0+q5vB2wSUR8UeQlBBwTEfPy/1IBD0bEvnMVSusUieVbEXGupOGk9/SkpG0i4sV5eH0zy+bnPtz6dAImS1oAGFhQ/gRpWwtqlX9L0rLAzIgYCgwG1q91ylNAf0lL5fr3LDg2Avi2iZCXW6vtAeDIfC2SVpO0aAPv50lgM0k/yNcsImk14EVgWUn9cnknSR2AGfkzqIljlYh4PiLOA0YDazTwemZWj0ofFlaOUQq/JyXGN0ldBDXJ51fADZJ+BdxWz7VrAxdImgN8AxxZeDAiJks6g/SVfjIwFmifDx8LXCLpOdL7fhQ4olb9/yB1fYxV+u7/AbBbsTcTER/klvqw3O8LcGpuje8N/C3fMPyC1K3xMHCSpHHAH4EfSdqS9C3gBeC+Yq9nZvVrgfVw3yA1imYDsyKir6QupPsxK5LWw90rIpo0P11R7YPzqswGG/SNJ54aXe4wql7nfnX3l1rL+nLcJWMiom9L1LXm2uvFtXc9UvScfisvUfT1csLtGxHTCsrOB6bn7r+TgM4RcWJTYvRMMzOrDq03LGwAMCQ/H0ID33qLccI1s+qhBh4Nb5MewAhJYwqOLR0RkyF1WwJNnrlTFTPNzMwaOdNsWgNdGJtFxHuSugMPSmrREUNu4ZpZVUgTH5rXpRAR7+V/pwJ3kLZEn5InVdVMrmry6ktOuGZWPRruUqj/0rR0QKea56SJUOOBu4CadVMGAXc2NTx3KZhZ1Wjm1N6lgTvybNAOwA0Rcb+kUcDNkg4B3mLu8f3zxAnXzKpGc9JtRLwOrFtH+YfA1s2o+ltOuGZWHVTnWiUVxQnXzKqCqIzpu8U44ZpZ1ajwfOuEa2bVw10KZmYlUuH51gnXzKqHE66ZWQmkuQ2VnXGdcM2sOlTIRpHFOOGaWfVwwjUzK4VGrRZWVk64ZlYValYLq2ROuGZWPZxwzcxKo5mrhbU6J1wzqxqVnW6dcM2sWrSB1cK844OZVYWa1cKKPYpeLy0v6WFJEyVNkPSrXH6GpHcljcuPnZoao1u4ZlY1mtm+nQX8JiLG5q12xkh6MB/7c0QMbmZ4TrhmVj2ac9Msb4Fesx36DEkTgZ4tFBrgLgUzqyYNbyLZVdLogsdhdVYjrQisBzyVi46W9JykqyV1bmp4TrhmVhXUwBbpeVLEtIjoW/C44vv1aDHgNuC4iPgUuBRYBehDagFf2NQYnXDNrGqogf81eL20ACnZXh8RtwNExJSImB0Rc4ArgQ2bGp8TrplVj4a7FOq/NI0puwqYGBF/KijvUXDa7sD4pobnm2ZmVjWauZbCZsABwPOSxuWy/wH2ldQHCOAN4PCmvoATrplVieatFhYRj1N3O/jeJldaixOumVUFb5NuZlZCTrhmZqUgrxZmZlYSjRiIUHZOuGZWPSo84zrhmlnVcJeCmVmJVHa6dcI1sypS6QuQKyLKHYPNA0kfAG+WO4551BWYVu4g5gNt8XNeISK6tURFku4nfQbFTIuIHVri9ZrCCddanaTREdG33HFUO3/Olc+L15iZlYgTrplZiTjhWil8b5FnaxX+nCuc+3DNzErELVwzsxJxwjUzKxEnXDOzEnHCtTZHlT6dqMr48245TrjWpkhS5Du9klYsczhVr9bnfYSk/uWNqG1zwrU2peCX/1jgZElLlzmkqlbwef8KOBSYWt6I2jYvXmNtjqRBwH7AgIiYImnxiPi03HFVk1ot22WAnwADgOmSdgeWBP4vIt4uX5RtjxOuVTxJHSJiVkHR6sAwoJOkg4D+kqZGxM/LE2F1kbQk8ANgtKSNSd+EPyRtGd4FmA2sCrQH/lGmMNskT3ywiiZpCWCviLhS0uGkJU+fBy4FJgP3AGOBI4HfRcR7ZQu2SkhaC/gZsC7QLSK2kLQzsBzwaERMlHQ00Ac4HJgTTiSN4hauVbSI+ERST0lTSctS7hARH0raEpgZEV9I2g1YC/iynLG2dZLaRcQc4DWgJ7ADcC5ARAwvOG8Q6Q/cHhExuxyxtlW+aWYVqdZQpBuACaQGwie5bDoQkvYHzgMOiIjppY2yeuQ+2zn5x+VIn+lvgCVza7bmvE2BHwF7RsTE0kfatrlLwSpOrRs2ewILR8S1kgYDmwG7R8T7kjYBZgIzIuL1MoZcNSQdBfwS2BSYRbpZ9mPgKdJn3QW4KSI+KluQbZgTrlWs/Mt/OKk19VIu+xup7/Ae4GBgi4iYUrYgq4ikrYHzgZ9GxJu5bDFge2BXYHNgZ7dsm84J1ypO7k5YGrgKOCoi3pDUMSK+yscPB3oB10fEC2UMtU0r/CaRf94e2DIiTpLUEfgmIubk/x4CloqID8oVbzXwTTOrCIW//BER+SbZ58Bqkt4pSLZrk4YiRUGfo82jghtkhc/fBfaUdE9EPJ6PHQ4QEZcDTrbN5IRrZVfrl39VoEMeejSJNDTpReAtSfsAPwUOi4iPyxZwFSj4vH8BbJg/60dJY23/IOkaYEHgF4DHN7cQJ1wru4Jf/uOBnYE5kl4BrgR+C6wvqR2wBrC/k23TSeoBfJyH0x0B7A2cCvwRWAQ4m3RzbC9gBvDziJhQrnirjROulY2krUj3ER6StC2wfURsLekPQL+IeCYnhRWA5YHnPZW06STtSroJuR/wBdCNNMHhZ6QxzKeTZo/dHxF3lyvOauaEa2UhaR3SbLGdcuv1XWCYpLOBDUgtXYB1I+Ix0uwyayJJ7UndMY8Aa0h6FegIjAJejIjt8nmHAl9Iut6TGlqeJz5YyUnqRBqFMAZYn9SyWg44Iv+8Q0R8nX/5z5HU2WuyNl3+JrEdMATYnTSkbiapy+YF0hjbmhlkxwJPOdm2Dg8Ls5LKK01tHxFHSHqOtAjKahHxtqQTgR2Bm4BlSMlhX/chNp2k3qSFfjYDtgQuAv4LXBIRj0vaHPgdqSthCdINSX/ercRdClYykhYntaCulrQe8DBpFaqzgQMj4jxJ7wOdgQUomPBgTdYdCNLEhZWB3YAfAgdL6hQR9wGPSVoK+DoiZpQt0vmAW7hWMrlb4CjS19sewEZ5YP0I0p3zvcoaYJWSNAboDfTJw+1WJM0eWw8YGRE3ljO++Yn7cK1k8sQGkRY/eYy0IhX5hs1ikobnG2jeR6sZaj67ms8SGAHcAdyaF2t/A7gXmAhsnKfvWgm4hWutqo7poz8EFgd2IS1kfXtEPJeP3QYcGxHvliXYKlBr4Z9NScO9xuebkFcAWwDrR8RMScsBn3lcc+k44VpJ5PG0vYA5wMVAV2AQ8DFwX0SMLV901SdPItmNtIbwysCgiHhV0mWk4WErRMQXZQxxvuQuBWt1eT3VPYC7gW2BYyJiPHAzaTjYNpI6uhuhZUjaAPhxRGxBGr/8GfAWQEQcQRoFsmz5Ipx/eZSClcLSpIkMR5JGJZyZV6MaTfrKO6VmcRprEVNI+5FdTNqbbJeI+EbSHhFxa0QcU+b45ltOuNaqcqu1F/AE8Abpl39OXoXq44i4qZzxVakOwJqkP3R75mR7EHCMpMe8fnD5uEvBWlW+gTOYNLD+sZxsDwSOI23+aC0sj0K4idQ/foakvwDHk7YhcrItI980sxZRezRCQXk70sD7zYFLSH2KqwAHefHwpivyeS8QEd/k5xuT+mq7Aw9GxGslDtNqccK1Zqs1FKkv8B4wu3ZrStKipDVW5Q0fm67W5/0r0o3HXqSbkVPrS8ZWfk641mIK1rN9kdSPeF7N5o6S2ntBlJaVFw/fm7R27TPArRHxm3zs20XdrXK4D9daRP76umNEbA0sSprcMEnSAgBOts0naU1JWxYU9eK7HRkmACdKWlBSByfbyuSEa00iaWOlHXRrdADGSvoN6e74gflr7YaSFipLkFVE0iKk9Q8OktQ/Fy9C2mizH2nr+FnAMcDR5YjRGuaEa001EfixpHPzzxOADUm7CewcEV9JOhI4hbTylzVR7pOdCVxH6q4ZlPd+uwJYB7gf+EbSQOAg0joJVoHch2vzJI+rVR7eNQC4DLgzr297KGkFqlnAq8AhpD3Ixpcv4uoh6TBgG9Lebs8DZ5LWsL0IeJ20AtuxXs+2cjnh2jypuQMu6VjSql+PAycDN5J2fF2d1Mr9ELjbQ7+aTlLHgu3hNyJtD78haSfjTYC1gTOAyaQunYU9+qOyeaaZNYqkPsA7ETEtLyQ+ADgjIh6TdDkwDlgoIo7Mz60Z8gLt20j6U77huBAwPS8486SkGaQRIRcD50fE46SNIa2CuQ/XGpRvem0GtJe0UER8CrwCLAaQW2GHAYdL+n35Iq0qLwLXAr2Vtjb/DzAtf7MgdxuMAp4jdd9YG+AuBWuUPLxrdeBcYH/SfmMHAYdExCuSdiLtmXWZZzQ1Xc2KabnbRsBdpIkkZwN9SK3apYCRpD7y3bx1fNvhhGv1qmPx8KVJGw52Ju2wW7NdzgxgLWBXJ9umqzWDbGtgPGlpxX8AbwOXA18Dh5OmS9/kG5JtixOu1anWL/+xwNIRcUreD+tI0q66vySNBe1J6l98q1zxVhNJxwEDgf3yt4fFSMl2GnCOp++2Xe7DtToVJNtfk6aODsuH3gQuJLW4bgQ6RMQ4J9uWIWkrUrL9UU62/YDVSLPJVgBOyNOknWzbII9SsHpJWpg0sH53oFNeVnEX4HTgSuBA/Ee7yepppb5NuhH2B0lzgI2Ar4DzScPtOnuadNvlLgWrV15a8RagE2lnhidIN25mRsQhXiCleSQtmDd37JCn5SKpG2lyw67An0ijQX4JvBsRQ8oXrbUEJ1yrU8EEh4VIN8aeiogpkrYjJYCBEfF5eaNsm/Log1WBh4F+EfFeYdKtde5+wG+BfSPixRKHai3MXQpW51fbnGwXjIgvSUOTatZePZg0XdfJtonyZ/2ypOuBkZJ+lG+EFbZ0OwJ9SUO/fu5kWx3cwp3P1RqNsBVpGFJExKhc1i6vm9Ce1Hc7LCImli/itq/g28OapAVpFgH6528Q364bnGf0tYuIj8sYrrUgJ1wDvh36dQBpIetVgPsiYnA+5r7aFpY/711J2w4NJN0c6xcR7xduk2PVxV0KhqRlgX1IExcmS/oh8A9Jb0XEzU62rWJt4C8RcQ9wh6Q/A/+WtFVEvF/m2KyVeEjPfKhm+mgtXwKfA+QugxtJExqsmWp/3nn0x9dA74Lii4COwD2S2tfz38jaOCfc+UytPttVASLiPeBl4LaCUzsBqyorfaTVodbnvY2k3kAX4K+kSQyH5lM3BP4G/DQiZntiQ3VyH+58pNYv/9HAscCTwH3AnaQZZBuTdgwYAOzhu+MtI8/Y24O06teywFmkBs8Q4CVSwh3gz7u6OeHOhyTtSpoxdh6wFbAm8GJEXC5pF6A98EJEvFLGMKuGpG2A30XEdkr7wG0AvENaAexFYGHS4uFTilRjVcAJdz4jqSfwX+D/IuJgSQsCPyXtIPAGcHneP8uaqGAoXc3wr/WAj4BtgX1Jy1r+gbTr7jkRcX8Zw7USch/ufCYi3gWOA3aQtE9EfA3cDIwFupNu3FgzFIzqWDX/Oy4i3iANtzsxIt4EXiNtT/Rc6SO0cvGwsPlQRNwu6Svgj5KIiBslXQcsGhEzyh1fWyVpU6BX/jyPAY6R9ATwaJ5VNgu4QdLfSWNwd803LG0+4YQ7n4qI4Xk1qiskzYqIW0kLiVvTdSb9EVsDWA7YkbQLxjqkZSxPlTSFtLvu/l7Scv7jPtz5nKRtgdci4vVyx1IN8uf5J+DJiPhFQR/5pqRuhEtzN47Nh9yHO5+LiAedbFtORDwInAoMqNVHPobUsl20nPFZeblLwayFRcSdkmbhPnKrxQnXrBW4j9zq4j5cs1bkPnIr5IRrZlYivmlmZlYiTrhmZiXihGtmViJOuGZmJeKEa2ZWIk64VhEkzZY0TtJ4SbdIWqQZdV0jaY/8/B95d9z6zu2fF52Z19d4Q1LXxpbXOuezeXytMySdMK8xWuVxwrVK8UVE9ImI3qT9vo4oPJi3aZ9nEXFoRLxQ5JT+pHUOzFqdE65VoseAH+TW58OSbgCez5srXiBplKTnJB0OaesgSRdLekHScNK6vuRjIyX1zc93kDRW0rOSHpK0Iimx/zq3rjeX1E3Sbfk1RknaLF+7lKQRkp6RdDnQ4D5vkv4laYykCZIOq3XswhzLQ5K65bJVJN2fr3ksrzpmVcRTe62iSOpAWtawZheEDYHeETEpJ61PIqKfpI7AE5JGAOsBq5O2Hl8aeAG4ula93YArgS1yXV0iYrqky4DPImJwPu8G4M8R8bikXsADwA+B04HHI+IsSTsDcyXQehycX2NhYJSk2yLiQ9ICNmMj4jeSTst1Hw1cARwREa9I2gj4O2kLJKsSTrhWKRaWNC4/fwy4ivRV/+mImJTLtwPWqemfBZYg7aqwBTAsImYD70n6dx31bww8WlNXREyvJ45tgDULNipeXFKn/Bo/zdcOl/RRI97TsZJ2z8+Xz7F+CMwBbsrlQ4HbJS2W3+8tBa/t3TeqjBOuVYovIqJPYUFOPJ8XFgHHRMQDtc7bCWhojroacQ6kbrZNIuKLOmJp9Dx4Sf1JyXuTiJgpaSSwUD2nR37dj2t/BlZd3IdrbckDwJGSFgCQtJqkRYFHgX1yH28P0i4Ltf0X+LGklfK1XXL5DKBTwXkjSF/vyef1yU8fBQbmsh1JuzsUswTwUU62a5Ba2DXakbZMB9iP1FXxKTBJ0p75NSRp3QZew9oYJ1xrS/5B6p8dK2k8cDnpW9odwCvA88ClwCO1L4yID0j9rrdLepbvvtLfDexec9MMOBbom2/KvcB3oyXOBLaQNJbUtdHQ9jj3Ax0kPUfaDv3JgmOfA2tJGkPqoz0rlw8EDsnxTQAGNOIzsTbEq4WZmZWIW7hmZiXihGtmViJOuGZmJeKEa2ZWIk64ZmYl4oRrZlYiTrhmZiXy/4v0Mx2Pnm7hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no side effects', 'had side effects']\n",
    "plot_confusion_matrix(cm , cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving model keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.isfile('models/medical_train_model.h5') is False:\n",
    "    model.save('models/medical_train_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calling a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('models/medical_train_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x1a6a2b2d7c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.76460797,  0.35020918,  0.4975256 ,  0.5056271 , -0.28207117,\n",
       "         -0.14149868,  0.51741034,  0.47181365,  0.4745398 ,  0.00330728,\n",
       "         -0.11058256, -0.02661705,  0.32607687,  0.33931696, -0.01568417,\n",
       "         -0.2698907 ]], dtype=float32),\n",
       " array([-0.14150336, -0.1508391 , -0.14730987,  0.21395348,  0.        ,\n",
       "         0.        , -0.17292495, -0.15971936, -0.13698006, -0.0034997 ,\n",
       "         0.        ,  0.        , -0.13118151, -0.14302318,  0.19560422,\n",
       "         0.        ], dtype=float32),\n",
       " array([[ 0.02444698, -0.30321956, -0.00443742,  0.28237274,  0.02805287,\n",
       "         -0.2890944 , -0.47498274, -0.2329671 ,  0.15470318,  0.10806578,\n",
       "         -0.11987507,  0.37846676,  0.07431003,  0.13717629, -0.2739766 ,\n",
       "         -0.21109775, -0.11177285, -0.11295592, -0.10630059,  0.10921159,\n",
       "         -0.28667164,  0.279856  ,  0.16674837,  0.16961597, -0.10335907,\n",
       "          0.12941435,  0.47694588,  0.2938791 , -0.28242704,  0.4818288 ,\n",
       "         -0.30214182, -0.14873065],\n",
       "        [-0.15197633, -0.6475709 ,  0.18510504,  0.13703305, -0.16427366,\n",
       "         -0.17385113, -0.28027177, -0.4939037 ,  0.13081165, -0.3932024 ,\n",
       "          0.33396843,  0.42311856, -0.09142974,  0.60933137,  0.25308666,\n",
       "         -0.59659475, -0.21829875, -0.26296446, -0.07776776,  0.02404888,\n",
       "         -0.22910699,  0.44275647, -0.25718057, -0.25934407,  0.13318741,\n",
       "          0.16328779,  0.21301511, -0.01565057, -0.39402097,  0.5284005 ,\n",
       "         -0.27503338,  0.4082577 ],\n",
       "        [-0.0844195 , -0.40872052,  0.41463688, -0.28026062,  0.29405484,\n",
       "          0.29880673,  0.05570305, -0.24192047,  0.49255306,  0.12432274,\n",
       "         -0.32972413,  0.19876851, -0.13561186,  0.23125717, -0.34913749,\n",
       "         -0.26488763, -0.18838477, -0.05925524,  0.07855338,  0.51496106,\n",
       "         -0.3965945 ,  0.2055574 , -0.1616442 , -0.32480752,  0.33278587,\n",
       "         -0.11298802,  0.37592804,  0.3240116 , -0.36932197,  0.38739988,\n",
       "         -0.32645506,  0.3262389 ],\n",
       "        [ 0.23294677,  0.22092256,  0.22080514, -0.29589614, -0.12729494,\n",
       "          0.2099566 ,  0.0830608 ,  0.01815201, -0.02569356, -0.26552916,\n",
       "         -0.21617801,  0.02842542, -0.07822296, -0.02800342, -0.31786972,\n",
       "          0.29760286, -0.13957211,  0.0654292 , -0.17659833,  0.34900394,\n",
       "          0.3280129 ,  0.34026748, -0.1371906 ,  0.2657077 , -0.05469784,\n",
       "         -0.31100953,  0.27266538,  0.15219878, -0.16733402, -0.16447029,\n",
       "         -0.23672444,  0.15107153],\n",
       "        [ 0.09848261, -0.1434715 , -0.17821829, -0.22474116, -0.13238847,\n",
       "         -0.02956694,  0.17284498,  0.10209769,  0.23100832, -0.0184781 ,\n",
       "         -0.33333412,  0.16500053,  0.2867963 ,  0.17906567,  0.14852801,\n",
       "          0.3190681 ,  0.1347025 ,  0.22237715, -0.12682037, -0.15210865,\n",
       "         -0.05130517,  0.20622149, -0.3331013 , -0.03133231, -0.34609357,\n",
       "          0.306106  ,  0.23259887,  0.08231601,  0.34726903, -0.2707746 ,\n",
       "          0.16816822,  0.25507763],\n",
       "        [-0.02787921,  0.06956995, -0.17924438, -0.02960429,  0.13302758,\n",
       "         -0.3284685 , -0.12708758,  0.32922414, -0.0462999 , -0.00756779,\n",
       "         -0.15942374,  0.2949504 , -0.3200828 ,  0.2417694 , -0.22075246,\n",
       "         -0.0722478 ,  0.3275948 , -0.24887553, -0.16295691, -0.09749231,\n",
       "         -0.0049611 ,  0.32950303,  0.13598663,  0.09071022, -0.17759822,\n",
       "         -0.02520272,  0.03285635, -0.2530018 ,  0.28178868, -0.24487048,\n",
       "          0.0920161 ,  0.23586944],\n",
       "        [-0.49926633, -0.23115216, -0.04482337,  0.09908447,  0.26030365,\n",
       "         -0.07701131,  0.00898671, -0.43646765,  0.51768696, -0.5391737 ,\n",
       "          0.03399774,  0.38817474, -0.05233812,  0.56373096,  0.02668199,\n",
       "         -0.56263006, -0.16162051,  0.32066   , -0.02680776, -0.05049461,\n",
       "         -0.35336626,  0.25698948,  0.18618879, -0.3313933 ,  0.09676117,\n",
       "         -0.10118994, -0.0043616 , -0.03152915, -0.23135144,  0.44672588,\n",
       "         -0.18580556,  0.39090618],\n",
       "        [-0.5351381 ,  0.03548178,  0.2383184 ,  0.25541824, -0.2005089 ,\n",
       "         -0.16358511,  0.04354368,  0.08151451,  0.45776787, -0.05220769,\n",
       "         -0.18592778,  0.13395277, -0.3499987 ,  0.3371844 ,  0.31892577,\n",
       "         -0.29592136, -0.32011527,  0.03128725, -0.22630067,  0.17848474,\n",
       "         -0.5998246 ,  0.25372723, -0.30700007,  0.00969363, -0.01557612,\n",
       "          0.06485775,  0.37867722,  0.50333655,  0.09306335, -0.10646442,\n",
       "         -0.1263775 , -0.05739941],\n",
       "        [-0.50034213, -0.14266871,  0.4169813 , -0.23658863, -0.16096589,\n",
       "          0.11112438, -0.24709433, -0.16444018,  0.10636225, -0.03406413,\n",
       "          0.08471155,  0.25473806,  0.070124  ,  0.4630766 ,  0.00237668,\n",
       "         -0.30363673, -0.15328287, -0.2252404 ,  0.12096989,  0.4369506 ,\n",
       "          0.05575231, -0.00469614, -0.16772886, -0.25997394, -0.31817412,\n",
       "          0.05618757,  0.1748058 ,  0.45150512,  0.02611585,  0.0908761 ,\n",
       "          0.34641263,  0.46143568],\n",
       "        [-0.25644144, -0.02037083,  0.04662094,  0.34440815, -0.31445628,\n",
       "          0.27708054, -0.17907694, -0.22755107,  0.18251978,  0.02376489,\n",
       "         -0.02033409, -0.07081607, -0.11305217, -0.05893426,  0.0261509 ,\n",
       "          0.06327958, -0.05878711,  0.01424422,  0.16301534,  0.07767991,\n",
       "          0.24842344,  0.35010093,  0.28729746,  0.10782095, -0.27320683,\n",
       "         -0.2497843 , -0.17961118, -0.0838794 , -0.2003683 ,  0.23386857,\n",
       "          0.20529386, -0.26361156],\n",
       "        [-0.12739019, -0.1775592 , -0.28599274,  0.23851904,  0.20824578,\n",
       "          0.04279533, -0.14725898, -0.11738285, -0.3026163 ,  0.25251177,\n",
       "          0.30176225, -0.22659259,  0.21325949, -0.2993705 ,  0.3124437 ,\n",
       "          0.25544026,  0.23841277,  0.23403403, -0.34829313, -0.11421417,\n",
       "          0.18283924,  0.23201421, -0.2612689 ,  0.14566523, -0.07898268,\n",
       "          0.2819427 ,  0.14235276,  0.13668308,  0.25763592, -0.34687606,\n",
       "         -0.16303016,  0.11654681],\n",
       "        [-0.33147088,  0.11297226,  0.33382872,  0.13615462,  0.12548795,\n",
       "         -0.2098843 ,  0.25375655, -0.19239092, -0.1357045 ,  0.1966646 ,\n",
       "         -0.18171158,  0.17678174,  0.28681198, -0.21813497,  0.08051676,\n",
       "          0.14774314, -0.0013063 , -0.22612357, -0.3124999 ,  0.04961517,\n",
       "         -0.13060431, -0.09294349,  0.23973909,  0.24414656,  0.3526388 ,\n",
       "          0.32007852, -0.27754468, -0.28673673,  0.04752606, -0.14298007,\n",
       "          0.1983997 ,  0.21482357],\n",
       "        [-0.4875178 , -0.58462477,  0.21476658, -0.29924902,  0.21614328,\n",
       "         -0.2539372 , -0.01949078,  0.0532006 ,  0.5702609 , -0.2814742 ,\n",
       "         -0.17676279,  0.46193904, -0.12818088,  0.47599396,  0.34291562,\n",
       "         -0.14729251,  0.07925671, -0.11817221, -0.21462895,  0.13325936,\n",
       "         -0.24265447,  0.41867688,  0.32548097, -0.48507503, -0.2246443 ,\n",
       "          0.08865699,  0.0720193 ,  0.19227317,  0.05191914,  0.47535795,\n",
       "         -0.34472126,  0.5702563 ],\n",
       "        [-0.55984414, -0.6225028 ,  0.431602  , -0.23420548, -0.29988596,\n",
       "         -0.11184833, -0.23602548, -0.45703548, -0.10353874, -0.5392333 ,\n",
       "         -0.07900116, -0.0770311 ,  0.31711742,  0.35209638,  0.00476891,\n",
       "         -0.05716481,  0.2016637 , -0.12668149,  0.11189905,  0.42132568,\n",
       "         -0.5766917 ,  0.50329554,  0.26370898, -0.33261877, -0.29745483,\n",
       "         -0.0582639 ,  0.05082675,  0.35806787, -0.18796477,  0.48129985,\n",
       "         -0.17097779,  0.5252761 ],\n",
       "        [ 0.3558378 ,  0.3931153 , -0.34158224, -0.25010943, -0.22206332,\n",
       "         -0.2996739 , -0.03078084,  0.39797238, -0.0943114 ,  0.19138175,\n",
       "          0.2062119 , -0.36187765, -0.16349453,  0.12717818,  0.05728678,\n",
       "          0.04799474,  0.18214257,  0.10141226, -0.11805299, -0.08566545,\n",
       "          0.21769592, -0.3639296 , -0.2922654 ,  0.33802205, -0.19984417,\n",
       "         -0.03678915, -0.30290318, -0.22625773,  0.5074696 , -0.00755446,\n",
       "          0.04985735,  0.09484426],\n",
       "        [-0.29579416,  0.04383019, -0.32806897,  0.02997205, -0.18458179,\n",
       "          0.01886696,  0.08538082,  0.2867662 , -0.05421188,  0.15349779,\n",
       "         -0.24408723, -0.15821135,  0.02554393,  0.1608015 ,  0.17401347,\n",
       "         -0.01001096,  0.02008307,  0.29073092,  0.31542584,  0.31708136,\n",
       "         -0.3260702 ,  0.17188379,  0.30494806, -0.18558303, -0.10769439,\n",
       "          0.30879894,  0.1652492 ,  0.15668485,  0.25141075, -0.04042262,\n",
       "         -0.27711543, -0.26393038]], dtype=float32),\n",
       " array([ 0.20021032,  0.25633505, -0.11531672, -0.00054094,  0.        ,\n",
       "        -0.01744585,  0.20489393,  0.22287302, -0.0996182 ,  0.267233  ,\n",
       "         0.        , -0.09919043,  0.        , -0.11567128,  0.00135302,\n",
       "         0.22874938, -0.00846398, -0.04122955,  0.        , -0.16305767,\n",
       "         0.20729078, -0.13382582,  0.        ,  0.17943314,  0.        ,\n",
       "         0.        , -0.13088143, -0.11862794,  0.23969056, -0.09820187,\n",
       "         0.        , -0.12122831], dtype=float32),\n",
       " array([[ 0.7127385 , -0.8801873 ],\n",
       "        [ 0.25132635, -0.8058942 ],\n",
       "        [-0.70726055,  0.20572516],\n",
       "        [-0.03005702,  0.00117029],\n",
       "        [ 0.1094062 , -0.27280426],\n",
       "        [-0.32876518, -0.10219947],\n",
       "        [ 0.5650145 , -0.14869583],\n",
       "        [ 0.78004104, -0.40208858],\n",
       "        [ 0.12107978,  0.5696564 ],\n",
       "        [ 0.23809627, -0.95168245],\n",
       "        [-0.29406846,  0.22645494],\n",
       "        [-0.65598017,  0.24870357],\n",
       "        [-0.13176683,  0.19020513],\n",
       "        [-0.5883438 ,  0.078518  ],\n",
       "        [ 0.14553867, -0.31072322],\n",
       "        [ 0.8293223 , -0.5528841 ],\n",
       "        [ 0.01818724,  0.20992072],\n",
       "        [ 0.27070278,  0.2883627 ],\n",
       "        [ 0.05157024,  0.00911129],\n",
       "        [-0.18257919,  0.30654693],\n",
       "        [ 0.54624355, -0.8359292 ],\n",
       "        [-0.22236969,  0.52242476],\n",
       "        [ 0.10693416, -0.03223985],\n",
       "        [ 0.48314154, -0.6061352 ],\n",
       "        [ 0.36635622,  0.05474097],\n",
       "        [-0.3071481 ,  0.13891783],\n",
       "        [-0.5726351 ,  0.43752667],\n",
       "        [-0.5900249 ,  0.5553277 ],\n",
       "        [ 0.6187134 , -0.6705526 ],\n",
       "        [-0.5621672 ,  0.12043285],\n",
       "        [-0.2388174 ,  0.1089206 ],\n",
       "        [-0.42471153,  0.6275563 ]], dtype=float32),\n",
       " array([ 0.16875768, -0.16875769], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model using JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()#model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.5.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json#model_form_yaml\n",
    "model_arch = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_arch.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save weights only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.isfile('models/medical_train_model_weights.h5') is False:\n",
    "    model.save_weights('models/medical_train_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
